# Scheduler y Gestión de Memoria Virtual - Sistema Operativo Rust ARMv8

El scheduler tiene una arquitectura modular manteniendo la filosofía KISS: "Keep It Stupidly Simple". Integra gestión de memoria virtual a través de la MMU (Memory Management Unit) de ARMv8 aarch64.

## Términos

1. **PCB (Process Control Block):** Estructura de ~1KB que guarda todo el contexto de un proceso (registros, stacks, estado, mailboxes).
2. **TTBR0_EL1 / TTBR1_EL1:** Registros de ARMv8 que apuntan a las tablas de páginas de userland (TTBR0) y kernel (TTBR1) respectivamente.
3. **EL0 / EL1:** Exception Levels del CPU; EL0 ejecuta procesos de usuario, EL1 ejecuta el kernel.
4. **IPI (Inter-Processor Interrupt) / SGI:** Interrupciones enviadas entre cores via GIC para coordinar eventos (TLB shootdown, mailboxes, migraciones).
5. **GIC (Generic Interrupt Controller):** Controlador ARM encargado de enrutar interrupciones entre cores.
6. **MMU (Memory Management Unit):** Hardware que traduce direcciones virtuales a físicas mediante tablas de 4 niveles.
7. **DMB/DSB/ISB:** Barreras de memoria ARM usadas para garantizar orden (Data/Instruction Memory Barrier).
8. **TLB (Translation Lookaside Buffer):** Caché de traducciones de la MMU que se invalida en migraciones o cambios de PTE.
9. **PTE (Page Table Entry):** Entrada individual de la tabla de páginas que describe la dirección física, permisos y atributos de una página de 4KB.
10. **Guard page:** Página marcada como `Fault` (sin permisos) colocada adyacente a un stack para detectar overflows mediante page fault controlado.
11. **DTB (Device Tree Blob):** Estructura provista por el bootloader con información del hardware, mapeada read-only en TTBR1.
12. **OOM (Out Of Memory) protection:** Reserva de 1MB que evita que userland deje sin memoria al kernel.
13. **SVC (Supervisor Call):** Instrucción de software que dispara una syscall (X8 define el ID).
14. **AtomicPtr:** Primitiva atómica de Rust usada para actualizar punteros de procesos sin condiciones de carrera.
15. **ASLR (Address Space Layout Randomization):** Técnica para randomizar base de heap/stack mediante PRNG LCG.
16. **Privileged binaries:** Tabla embebida que simula binarios `setuid` hasta que exista filesystem real.
17. **Mailbox:** Par de buffers `request/response` en el PCB que sincroniza syscalls entre Core N y Core 0.
18. **CNTVCT_EL0:** Contador de tiempo de ARM usado como entropy en el PRNG y para medir tiempo de CPU.
19. **ABA problem:** Condición de concurrencia en pilas lock-free donde un valor vuelve a su estado original y engaña a `compare_exchange`; se evita con tags o locks.
20. **Treiber stack:** Pila lock-free basada en `compare_exchange` usada para el `free_list` de PCBs.
21. **-EAGAIN:** Código de error estándar (errno 11) que indica que el recurso no está disponible temporalmente; se usa para cuotas de procesos.
22. **-EINVAL:** Errno 22; parámetros inválidos (por ejemplo, UID fuera de rango en `sys_exec`).
23. **-ENOEXEC:** Errno 8; imagen ELF inválida.
24. **-EFAULT:** Errno 14; puntero fuera del rango de memoria de usuario.

## Principios de Implementación

1. Todo debe estar escrito en Rust y ensamblador específico de la arquitectura.

2. Las operaciones atómicas y críticas a nivel de CPU se implementan en ensamblador usando la macro `asm!` de Rust, encapsuladas en funciones Rust individuales.

3. Las funciones de Rust que encapsulan las operaciones de ensamblador se utilizan a alto nivel para ejecutar las operaciones del scheduler.

**Razón:** Esto permite aprovechar optimizaciones específicas de ARMv8 aarch64, facilitando la portabilidad futura a otras arquitecturas sin modificar la lógica de alto nivel del scheduler.

## Organización del Código

4. La estructura de directorios debe ser:
   - `cpu/mod.rs`: archivo principal que exporta los módulos
   - `cpu/scheduler.rs`: lógica principal del scheduler (alto nivel)
   - `cpu/aarch64.rs`: funciones Rust con ensamblador específicas para ARMv8
   - `memory/mod.rs`: gestión de memoria virtual y física
   - `memory/mmu.rs`: operaciones de la MMU
   - `memory/page_allocator.rs`: gestor de memoria física mediante bitmap
   - `syscall/mod.rs`: interfaz de syscalls
   - `exception/mod.rs`: manejo de excepciones y interrupciones

5. El archivo `cpu/scheduler.rs` utiliza las funciones de `cpu/aarch64.rs` según la configuración de compilación. El target `aarch64-unknown-none-softfloat` en el comando `cargo build` determina qué módulo de arquitectura se compila.

**Razón:** Permite compilación condicional por arquitectura sin duplicar lógica de scheduling.

## Arquitectura de Ejecución

6. El scheduler se divide en dos dominios bien definidos:
   - **Dominio kernel (Core 0, siempre en EL1):** ejecuta un scheduler completo para procesos/threads del kernel y administra la tabla maestra de procesos de usuario.
   - **Dominio usuario (Cores 1-N, siempre en EL0 cuando ejecutan procesos):** consumen punteros y órdenes entregadas por Core 0; solo escalan temporalmente a EL1 para manejar interrupciones/SVC y volver a EL0 inmediatamente.
   Cada dominio mantiene su propio PCB y estado de scheduler, evitando mezclar procesos kernel y user.

7. Core 0 (principal) tiene su **propio scheduler y `kernel_process_table: [ProcessControlBlock; KERNEL_MAX_PROCESSES]`**. Solo ejecuta threads del kernel, maneja interrupciones críticas y nunca intercambia a código user. Core 0 también posee un PCB dedicado para sí mismo cuando está ejecutando tareas del kernel.

8. Responsabilidades exclusivas de Core 0:
   - Mantener la **tabla maestra de usuarios (`user_process_arena`)**: un conjunto de slabs dinámicos de PCBs ubicados únicamente en TTBR1 y capaces de crecer mientras exista memoria en el espacio virtual del kernel.
   - Crear/destruir procesos y espacios de direcciones de usuario
   - Asignar/liberar memoria física y tablas de páginas completas
   - Gestionar todos los `mailbox`, validar syscalls y rutear su resultado
   - Modificar punteros de scheduling por core mediante operaciones atómicas
   - Enviar IPIs para context switches, invalidación de TLB y migraciones
   - Administrar límites globales (topes por UID, cuotas de memoria, etc.)

9. Cores 1-N ejecutan exclusivamente procesos de usuario tomados de la tabla maestra. No tienen tabla propia: sólo leen (vía punteros provistos por Core 0) el PCB que deben restaurar. Permanecen en EL0 durante la ejecución normal y dependen de syscalls/IPI para cualquier interacción con el kernel. Todo acceso a la tabla maestra ocurre desde EL1 y únicamente durante la ventana del handler del núcleo secundario, lo que impide que código user lea PCBs.

10. **Scheduling centralizado en Core 0:** Cada 5 ms, Core 0 evalúa el campo `priority` de los procesos accesibles y decide qué PID debe ejecutar cada Core N:
    1. Solo Core 0 recibe el timer interrupt y corre el algoritmo completo.
    2. Core 0 escanea `user_process_arena` (estados CREATED/ASSIGNED/RUNNING) y `kernel_process_table` (solo para sí mismo).
    3. Calcula el mejor candidato para cada Core N (prioridad ascendente); aplica `round-robin FIFO` para desempates en un mismo core.
    4. Cuando detecta migración (nuevo proceso vive en Core M diferente), Core 0 coordina la pausa ordenada: espera a que Core M termine la instrucción o syscall en curso, luego envía IPI, recibe contexto completo y recién entonces actualiza el puntero.
    5. Antes de publicar un PCB, Core 0 verifica `claim_flag`: usa `swap(true, Acquire)` para reservarlo. Si ya estaba en `true`, busca otro candidato para evitar que dos cores lean el mismo PCB.
    6. Los punteros `current_process_ptr[core_id]` se actualizan con `AtomicPtr` (store con orden Release) y los cores lectores usan cargas Acquire para evitar lecturas parciales.
    7. Tras escribir el nuevo puntero, Core 0 envía IPI al Core destino para que cargue el PCB, restaure registros y marque estado RUNNING. Cuando Core N deja de ejecutar ese PCB (por cambio de estado, syscall o migración) ejecuta `claim_flag.store(false, Release)`.

    **Protocolo detallado de migración:**
    1. Core 0 marca al proceso actual en Core M como "pendiente de migración" y espera a que Core M termine la instrucción en curso o salga del handler si estaba en syscall.
    2. Core 0 envía IPI de pausa; Core M entra a EL1, guarda todo el contexto (X0-X30, SP user, SP kernel, FP regs, TTBR0, TPIDR_EL0) en su PCB y marca estado `ASSIGNED`.
    3. Core 0 actualiza `owner_core` del PCB, realiza `store_release` en el puntero del Core destino y copia cualquier dato adicional requerido.
    4. Core 0 invalida TLB del Core origen mediante SGI, espera confirmación y luego envía SGI al Core destino para que invalide su propio TLB.
    5. Core destino ejecuta `load_acquire`, restaura el contexto, marca el PCB como `RUNNING` y reanuda en EL0.

## Estados y Ciclo de Vida del Proceso

11. **Estados de proceso:**
    - `CREATED`: PCB reservado por `sys_exec`, todavía sin core asignado
    - `ASSIGNED`: Core 0 fijó un destino y está listo para ser cargado
    - `RUNNING`: Se está ejecutando en un Core N (EL0) o en Core 0 si es kernel thread
    - `SLEEPING`: Suspendido hasta que un evento/timeout lo reactive
    - `WAITING_SYSCALL`: Core N envió syscall y espera respuesta de Core 0 (mailbox lleno)
    - `ZOMBIE`: Proceso ejecutó `exit()`, liberó memoria propia, pero su PCB conserva `exit_code` hasta que el padre haga `wait()`
    - `TERMINATED`: PCB y recursos eliminados completamente (post `wait()` o reaper `init`)

12. **Transiciones de estado:**
    - `CREATED` → `ASSIGNED`: Core 0 valida cuotas (incluye límite de 10 000 procesos por UID≠0) y elige Core destino
    - `ASSIGNED` → `RUNNING`: Core destino recibe puntero válido y restaura registros
    - `RUNNING` → `WAITING_SYSCALL`: Proceso ejecuta `SVC` y deja su contexto en el PCB
    - `WAITING_SYSCALL` → `RUNNING`: Mailbox recibe respuesta; Core N hace Acquire load y vuelve a EL0
    - `RUNNING` → `SLEEPING`: Futuro `sys_nanosleep`/eventos
    - `SLEEPING` → `ASSIGNED`: Evento o wake explícito
    - `RUNNING` → `ZOMBIE`: `sys_exit` o señal letal; se liberan heap/stack/tablas, pero PCB queda con `exit_code`
    - `ZOMBIE` → `TERMINATED`: Padre usa `sys_wait` y Core 0 libera PCB; si el padre murió, `init` (PID 1) reaper automático
    - Cualquier estado → `TERMINATED`: Violación de memoria severa o fallo interno fuerza limpieza por Core 0

## Estructura de Datos - Tabla de Proceso

13. **Tabla de proceso (Process Control Block - PCB):**
    Cada entrada contiene:
    - `pid: u64`: Process ID único (max u64)
    - `uid: u32`, `gid: u32`: User ID y Group ID del propietario
    - `priority: u32`: Prioridad de scheduling (menor número = mayor prioridad)
    - `state: ProcessState`: Estado actual (CREATED, ASSIGNED, RUNNING, SLEEPING, WAITING_SYSCALL, ZOMBIE, TERMINATED)
    - `claim_flag: AtomicBool`: Indica si el PCB está reservado para un Core en particular; evita que el scheduler lo entregue dos veces.
    - `owner_core: u8`: Núcleo que ejecuta este proceso (0-N)
    - `is_running: bool`: Flag para dormir/despertar (si false, no se ejecuta) - reservado para futuro soporte de eventos
    - `pc: u64`: Program Counter (instruction pointer)
    - `sp: u64`: Stack Pointer
    - `lr: u64`: Link Register (X30)
    - `pstate: u64`: Processor State flags
    - `tpidr_el0: u64`: Thread-local storage pointer
    - `registers: [u64; 30]`: X0-X29 (general purpose registers)
    - `fp_registers: [u128; 32]`: V0-V31 (NEON/floating-point registers, 128-bit cada uno)
    - `fpcr: u64`: Floating-Point Control Register
    - `fpsr: u64`: Floating-Point Status Register
    - `ttbr0: u64`: Translation Table Base Register 0 (tabla de páginas)
    - `page_table_permissions: u32`: Flags de permisos sobre tabla de páginas del proceso
    - `kernel_stack_base: u64`: Base del stack de kernel privado del proceso (per-thread)
    - `kernel_stack_top: u64`: Tope actual del stack de kernel (crece dinámicamente en bloques de 64KB)
    - `kernel_stack_guard_page: u64`: Dirección de la guard page que dispara fault ante overflow
    - `kernel_stack_chunks: u32`: Cantidad de bloques de 64KB actualmente asignados (sin límite superior, solo RAM disponible)
    - `user_stack_base: u64`: Base de stack del usuario (parte de memoria virtual del proceso)
    - `user_stack_size: usize`: Tamaño actual de stack de usuario (dinámico, inicial 64KB, crece en bloques de 64KB sin límite hasta RAM disponible)
    - `binary_path: [u8; 256]`: Ruta absoluta al binario ejecutable
    - `argv: *const *const u8`: Puntero a argumentos del programa (vive en memoria virtual del proceso)
    - `argv_kernel_copy: [u8; 1024]`: Copia de argv en kernel para debugging
    - `argc: usize`: Cantidad de argumentos
    - `exit_code: i32`: Código de salida (cuando termina)
    - `cpu_time_ms: u64`: Tiempo CPU consumido en milisegundos
    - `creation_time: u64`: Timestamp de creación (en milisegundos desde boot)
    - `signal_pending: u64`: Bitmap de signals pendientes (futuro soporte)
    - `mailbox_request: Option<SyscallRequest>`: Solicitud syscall en progreso
    - `mailbox_response: Option<SyscallResponse>`: Respuesta de Core 0
    - **Tamaño total aproximado:** ~1KB por PCB (con registros FP: 512 bytes adicionales)

14. **Tablas de procesos separadas:**
    - `kernel_process_table`: arreglo fijo `[ProcessControlBlock; KERNEL_MAX_PROCESSES]` reservado únicamente para Core 0 y sus threads internos. Siempre reside en TTBR1 (mapeo 1:1) y jamás se expone a Cores 1-N.
    - `user_process_arena`: colección dinámica de slabs de PCBs dedicada a procesos usuario. Cada slab contiene 64 PCBs contiguos (≈64KB) y se reserva desde un rango virtual del kernel `0xFFFF_9000_0000_0000+` que nunca se mapea en TTBR0. Cuando el `free_list` queda vacío, Core 0 toma otra página física del pool de kernel, la mapea en TTBR1 y la inicializa como nuevo slab, por lo que no existe un límite fijo de procesos: la única barrera es la memoria disponible (`RAM_total - kernel - 4MB`).
    - Ambas tablas viven solo en TTBR1_EL1 y se marcan como **no mapeadas en TTBR0** de los procesos user. Cuando un Core N necesita leer/escribir su PCB lo hace desde EL1 dentro de su handler; en EL0 no existe ningún mapeo que permita inspeccionar PCBs ajenos.
    - El número máximo de procesos por UID no-root es 10 000; Core 0 rechaza `sys_exec` con `-EAGAIN` si excede este tope para evitar fork-bombs.
    - Para evitar que dos cores asignen el mismo PCB simultáneamente, cada entrada tiene un `claim_flag: AtomicBool`. El scheduler solo entrega un PCB si `claim_flag.swap(true, Acquire)` retorna `false`. Al liberar el PCB (cuando Core N sale de él) se ejecuta `claim_flag.store(false, Release)` y se permite otro CORE.
    - Core 0 mantiene una lista libre/ocupada para cada tabla y recicla PCBs únicamente después de que el estado llega a `TERMINATED`.

    **Gestor de cuotas y saturación (implementación recomendada):**
    1. `ProcessQuotaManager`: estructura global con:
       - `global_in_use: AtomicU32` (procesos activos en `user_process_arena`).
       - `per_uid: [AtomicU16; 1001]` que cubre UID 1000-2000 (los no-root). `UID 0` usa un contador dedicado `root_in_use: AtomicU16` (sin tope adicional porque sólo existe un root simultáneo).
       - `free_list`: pila Treiber sobre `AtomicU128` (`ptr: u64`, `tag: u64`) para evitar ABA. Cada `push` incrementa el tag, de modo que un `compare_exchange` que vea el mismo puntero pero distinto tag detecta la modificación intermedia.
       - `ProcessArena`: responsable de mapear nuevos slabs cuando el `free_list` queda vacío; su función `grow_if_needed()` intenta reservar otra página del rango kernel y, si falla por falta de memoria, retorna `Err(SysError::EAGAIN)`.
    2. `sys_exec` ejecuta `reserve_slot(uid)` antes de tocar memoria:
       - Si `free_list` está vacío, invoca `ProcessArena::grow_if_needed()` y solo si vuelve a estar vacío después de crecer retorna `-EAGAIN` (no hay VA ni RAM disponibles).
       - Calcula el índice del UID: `idx = uid - 1000` para usuarios comunes; UID 0 pasa por el contador especial.
       - Verifica `per_uid[idx] < 10_000`; si alcanzó el tope retorna `-EAGAIN`.
       - Usa `compare_exchange_weak` tanto en `global_in_use` como en el contador por UID; si alguna CAS falla se reintenta completo para evitar desbalance.
       - Para evitar ABA en el `free_list`, cada nodo incluye un `next_ptr` y un `tag`. Solo cuando el CAS de la pila tiene éxito se considera reservado el PCB.
    3. Al completar `sys_exec`, el índice reservado se marca con `state = CREATED` y `claim_flag.store(true, Release)` para impedir reasignaciones mientras se inicializa. Si falla a mitad (por ejemplo ENOMEM), se llama `rollback_slot(uid, index)` que vuelve a poner el nodo en la pila (con nuevo tag) y decrementa los contadores.
    4. `sys_exit` cambia el estado a `ZOMBIE` y, tras `sys_wait`, `release_slot(uid, index)` realiza `claim_flag.store(false, Release)`, decrementa los contadores y empuja el índice al `free_list` con un tag incrementado.
    5. Esta táctica garantiza que la detección de saturación (global o por UID) se haga antes de consumir memoria significativa, y que el mismo `-EAGAIN` se devuelva para falta de quota o de espacio en el arena.

15. **Punteros de scheduling por Core:**
    - Cada Core N posee `AtomicPtr<ProcessControlBlock>` con su contexto actual.
    - Core 0 escribe usando `store(Ordering::Release)` después de terminar de copiar registros y sólo luego emite la IPI correspondiente. Core N lee con `load(Ordering::Acquire)` dentro del handler, garantizando que no lea direcciones parciales.
    - El arreglo `[current_process_ptr; NUM_CORES]` reside en TTBR1. Para facilitar lecturas rápidas en EL0, cada Core mapea **solo su propia entrada** en una página dedicada marcada read-only en TTBR0; esa página no contiene PCBs ni datos sensibles, únicamente el puntero alineado de 64 bits.
    - Toda modificación ocurre desde Core 0; la comunicación hacia Cores 1-N se serializa mediante IPIs y barreras `DMB ish` después de escribir el puntero.

### Estructuras auxiliares y layout de mailbox

Para evitar ambigüedades se fijan las estructuras que participan en la reserva/liberación de memoria y en la ruta de syscalls. Todas usan `#[repr(C)]` y alineaciones explícitas para facilitar el ensamblador.

```rust
#[repr(C)]
pub enum FrameSource {
    KernelReserve,
    KernelStack,
    UserStack,
    UserHeap,
    PageTable,
    GuardPage,
}

bitflags::bitflags! {
    pub struct FrameFlags: u16 {
        const ZEROED     = 1 << 0;
        const DIRTY      = 1 << 1;
        const GUARD      = 1 << 2;
        const OOM_FALLBACK = 1 << 3;
    }
}

#[repr(C)]
pub struct PageFrameDescriptor {
    pub phys_addr: u64,      // Dirección física alineada a 4KB
    pub page_count: u16,     // Cantidad de frames contiguos (para bloques de 64KB)
    pub source: FrameSource,
    pub flags: FrameFlags,
}

#[repr(C)]
pub struct ProcessMemoryPlan {
    pub kernel_stack: PageFrameDescriptor,
    pub user_stack_segments: ArrayVec<PageFrameDescriptor, 32>,
    pub heap_segments: ArrayVec<PageFrameDescriptor, 256>,
    pub page_tables: ArrayVec<PageFrameDescriptor, 32>,
    pub guard_pages: ArrayVec<PageFrameDescriptor, 8>,
    pub ttbr0_phys: u64,
    pub state: PlanState, // Draft → Committed → RolledBack
}

#[repr(C, align(64))]
pub struct SyscallRequest {
    pub syscall_number: u32,
    pub argc: u32,
    pub args: [u64; 6],
    pub pid: u64,
    pub timestamp_ns: u64,
}

#[repr(C, align(64))]
pub struct SyscallResponse {
    pub return_code: i64,
    pub data: [u64; 4],
    pub errno: i32,
    pub flags: u32, // bit0=has_data, bit1=needs_ipi, bit2=retry_allowed
}

#[repr(C, align(64))]
pub struct ProcessMailbox {
    pub request: MaybeUninit<SyscallRequest>,
    pub response: MaybeUninit<SyscallResponse>,
    pub state: AtomicU32, // 0=Idle,1=RequestReady,2=Processing,3=ResponseReady
    pub padding: [u8; 32], // 3 líneas de caché completas (192 bytes totales)
}
```

- El campo `mailbox` del PCB apunta a esta estructura fija (offset +512 bytes dentro de cada PCB) para que los handlers en ensamblador puedan referenciarla con `add`.  
- `ProcessMemoryPlan` acumula todos los `PageFrameDescriptor` que se deben limpiar en caso de rollback. Se libera en orden inverso tal como se describió en la pipeline de `sys_exec`.  
- Las estructuras de mailbox están alineadas a 64 bytes para evitar falsas comparticiones cuando Core N escribe la request y Core 0 escribe la response. El bit `state` se avanza mediante `compare_exchange` con orden Acquire/Release tal como se hace en Linux para su mecanismo de `futex` dentro del kernel.

## Gestión de Memoria Virtual y MMU

### Configuración de registros ARMv8 (baseline Linux)

Se replica la configuración usada por el kernel Linux 6.6 sobre SoCs BCM2711/BCM2712 (páginas de 4KB y 48 bits de VA). Se listan los campos relevantes para poder recalcularlos si cambian los targets.

- **`TCR_EL1` (valor de referencia `0x10B5_19B5`):**
  1. `T0SZ = T1SZ = 16` (`bits[5:0]` y `bits[21:16]`) → espacios virtuales de 48 bits.  
  2. `TG0 = 0b00`, `TG1 = 0b10` (`bits[15:14]`, `bits[31:30]`) → cuarta parte de 4KB en ambos espacios.  
  3. `IRGNx/ORGNx = 0b01` (`bits[9:8]`, `bits[11:10]`, `bits[25:24]`, `bits[27:26]`) → Write-Back Write-Allocate para tablas user/kernel.  
  4. `SH0 = SH1 = 0b11` → Inner Shareable (`bits[13:12]`, `bits[29:28]`).  
  5. `AS = 1` (`bit 36`) para ASID de 16 bits.  
  6. `TBI0 = 1` y `TBID0 = 0` (`bit 37`) → se ignoran los 8 bits altos de punteros userland permitiendo usar direcciones canónicas con tags.  
  7. `EPD0 = EPD1 = 0` → se permiten caminatas de tabla completas (`bits 7 y 23`).  
  8. `IPS = 0b010` (`bits[34:32]`) → 40 bits de PA para Cortex-A72/A76 según `ID_AA64MMFR0_EL1`. El valor se recalcula en tiempo de arranque leyendo el registro para soportar futuros SoC con 44/48 bits.  
  9. `HA = 1`, `HD = 0` (`bits 39 y 40`) → hardware actualiza Access Flag mientras que Dirty Bit queda en software, igual que Linux.  
  10. Cuando se compila con `--features kasan`/`mte`, se replica el comportamiento de Linux habilitando `TBI1|TBID1` (bits 38 y 59) para tener tags en TTBR1; por defecto permanecen en 0.

- **`MAIR_EL1` (valor `0x0004_0044_F0FF`):**
  - Índice 0 (`MT_NORMAL`) = `0xFF` (WB/WA caché normal).  
  - Índice 1 (`MT_NORMAL_TAGGED`) = `0xF0` (WB/WA apto para MTE).  
  - Índice 2 (`MT_NORMAL_NC`) = `0x44` (Normal no-cacheable).  
  - Índice 3 (`MT_DEVICE_nGnRnE`) = `0x00` (dispositivo fuertemente ordenado).  
  - Índice 4 (`MT_DEVICE_nGnRE`) = `0x04` (Device nGnRE).  
  - Los índices adicionales quedan reservados para futuras plataformas pero se inicializan en cero para reproducir el layout de Linux.

- **`SCTLR_EL1` (`INIT_SCTLR_EL1_MMU_ON = 0x34D5_1993`):**
  - `M|C|I = 1` → MMU + cachés habilitados.  
  - `SA|SA0 = 1`, `SPAn = 1`, `nTWE = 1`, `nTLSMD = 1`, `LSMAOE = 1` → mismo set de protecciones ante especulación que Linux, previniendo accesos fuera de orden en memcpy del kernel.  
  - `SED = 1`, `DZE = 1`, `UCT = 1`, `UCI = 1` → syscalls que requieran instrucciones DC/IC desde EL0 generan trap gestionado por Core 0.  
  - `IESB = 1`, `ITFSB = 1`, `EPAN = 1` → asegura broadcast de faults y PAN especulativo idéntico al upstream.  
  - `WXN` permanece en 0 (Linux también lo deja desactivado) porque la política W^X se hace a nivel de tablas; puede activarse por feature en SoC más restrictivos.

- **GIC-400 (según `drivers/irqchip/irq-gic.c` de Linux):**
  - `GICD_CTLR = GICD_CTLR_ARE_NS | GICD_CTLR_EnableGrp0 | GICD_CTLR_EnableGrp1NS` (`0x13`) para permitir SGI vía MPIDR y habilitar Grupos 0/1NS.  
  - `GICC_CTLR = EnableGrp0 | EnableGrp1 | FIQEn` (`0x07`) y `GICC_PMR = 0xF0` antes de salir del boot.  
  - `GICR_WAKER`: se limpia `ProcessorSleep` y se espera `ChildrenAsleep == 0` antes de enviar IPIs, igual que `gic_starting_cpu()` en Linux.  
  - Las prioridades se inicializan en `0xA0` y los registros `GICD_IPRIORITYR` mantienen el mismo orden (SGI > Timer > PPI > Otros) para asegurar paridad con la configuración de Linux y facilitar comparaciones.

16. **Mapa de memoria físico/virtual del sistema:**
    - **Rango kernel:** Bootloader deposita el binario en memoria baja y Core 0 inicializa TTBR1_EL1 con un mapeo 1:1 (PA=VA) para código/datos del kernel, bitmap, tablas de procesos y DTB. El DTB se marca read-only tras el arranque para evitar modificaciones accidentales o maliciosas.
    - **Datos sensibles:** `kernel_process_table`, `user_process_arena`, mailboxes y bitmap de páginas solo existen en TTBR1. TTBR0 de los procesos usuario no mapea ninguna de estas regiones.
    - **Stacks de kernel per-thread:** Cada PCB administra su stack propio en rango kernel. Se inicia con 64 KB + una guard page sin permisos. Cuando queda <4 KB libres se dispara un fault controlado y Core 0 asigna otro bloque de 64 KB usando el `page_allocator`. No hay límite superior para el kernel: mientras exista memoria en el pool reservado o en el bitmap global, puede seguir creciendo.
    - **Algoritmo de guard page:**
        1. Layout por stack: `[guard page sin permisos][chunk_n][chunk_{n-1}] ... [chunk_0]`, creciendo hacia direcciones bajas.
        2. Durante cada cambio de contexto a EL1, Core N ejecuta `monitor_kernel_sp()`: si `sp_kernel - guard_top < 512 bytes`, se adelanta una solicitud `StackGrow` al Core 0 antes de que ocurra el fault.
        3. Si igualmente se genera un page fault sobre la guard page, el handler la reconoce por dirección y la trata como “crecimiento legítimo”. Core 0 asigna un nuevo chunk, mueve la guard page una página más abajo (actualizando su PTE a `Fault`), limpia el chunk con ceros y actualiza `kernel_stack_chunks`.
        4. Si Core 0 no puede asignar el nuevo chunk (por falta de memoria en el pool reservado), se dispara `panic!` porque el kernel no puede continuar sin stack seguro.
        5. Para stacks de usuario se aplica la misma lógica pero con `sys_page_fault`: la guard page se ubica al final del rango virtual del stack y sólo se mueve si la cuota de memoria user lo permite.
    - **Stack de Core 0:** Sigue la misma política de guard page y crecimiento incremental pero nunca se comparte con syscalls de usuario.
    - **Reservas de kernel:** 3 MB fijos para operaciones críticas + 1 MB para OOM protection conforman un pool de 4 MB que jamás se asigna a procesos en Cores 1-N. Ese pool abastece las expansiones de stacks de kernel y cualquier asignación urgente que mantenga a Core 0 siempre responsivo.
    - **Stacks y heap de usuario:** El stack vive en `[0x7FFFFFFFFFFF ↓ 0x70000000]` y el heap en `[0x00000000 - 0x6FFFFFFF]`, ambos creciendo bajo demanda mediante page faults.
    - **Rango user:** Todo espacio restante utiliza TTBR0_EL1 con tablas de 4 niveles; ASLR determina offsets distintos por proceso.
    - **Separación estricta de VA:** El kernel solo ocupa las direcciones altas `0xFFFF_8000_0000_0000+`, mientras que userland queda confinado a `0x0000_0000 - 0x7FFF_FFFF_FFFF`. Los allocators (incluyendo `user_process_arena`, stacks y tablas de páginas) nunca asignan páginas fuera de su mitad correspondiente, evitando cualquier colisión entre VA de kernel y de usuario.
    - **Acceso por core:** Core 0 opera únicamente en EL1 con TTBR1. Cores 1-N ejecutan en EL0 y solo ven unas pocas páginas del kernel (vector table, stubs de syscall) en read-only.

### Direccionamiento de periféricos derivado del DTB

En lugar de codificar constantes, se parsea el Device Tree que entrega el firmware y se llena una estructura común:

```rust
#[derive(Copy, Clone)]
pub struct PeripheralsLayout {
    pub mmio_start: u64,
    pub uart_pl011: u64,
    pub gpio: u64,
    pub spi0: u64,
    pub gic_distributor: u64,
    pub gic_redistributor: u64,
    pub local_intc: u64,
}
```

- **RPi 4B+ (DTB `bcm2711-rpi-4-b.dtb`):** el nodo `/soc` define `ranges = <0x7e000000 0x0 0xfe000000 0x01800000>` y `interrupt-controller@40041000`. Se suman `0x8000_0000` a todas las direcciones de `/soc` generando: `PL011=0xFE201000`, `GPIO=0xFE200000`, `SPI0=0xFE204000`, `GICD=0xFF841000`, `GICR=0xFF842000`, `local_intc=0xFF800000`.  
- **RPi 5 (DTB `bcm2712-rpi-5-b.dtb`):** el `ranges` mapea `<child_address, 0x10, parent_address, size>`, por lo que basta concatenar `0x10` como los bits altos: `PL011=0x107D001000`, `GPIO=0x107D200000`, `SPI0=0x107D204000`, `GICD=0x107FFF9000`, `GICR=0x107FFFA000`, `local_intc=0x107C001000`.  
- Si falta algún nodo imprescindible (`serial`, `gpio`, `spi0`, `interrupt-controller`), el kernel aborta el boot para evitar usar valores incorrectos.  
- Esta estructura se exporta desde `bsp::raspberrypi::<board>::memory::map` y es la única fuente de verdad para los drivers, lo que facilita incorporar nuevas plataformas (Raspberry Pi 5, Allwinner, etc.) simplemente añadiendo nuevos extractores de DTB y correspondientes `cargo --features bsp_<board>`.

17. **Tabla de páginas (4 niveles - ARMv8 format):**
    - Estructura idéntica a Linux kernel ARMv8
    - Niveles: L0 (PGD), L1 (PUD), L2 (PMD), L3 (PTE)
    - Tamaño de página: 4KB
    - Espacio virtual soportado: 48-bit (256TB)
    - **Page Table Entry (PTE) contiene:**
      - Valid bit: página mapea a memoria física válida
      - Permissions (AP bits): read/write/execute, kernel vs user
      - Physical address: dirección física de 4KB
      - Accessed bit: 1 si se accedió recientemente
      - Dirty bit: 1 si se escribió
      - Shareability bits: para coherencia entre cores
      - Contiguity bits: optimización de TLB
    - **Ciclo de vida de tablas:**
      1. Core 0 asigna tablas (L0-L3) del mismo bitmap de memoria física que usa para páginas de datos.
      2. Core 0 las mapea read-only en rango kernel (TTBR1_EL1) para poder editarlas desde EL1.
      3. Procesos user cargan la tabla L0 en TTBR0_EL1.
      4. Al terminar un proceso, Core 0 libera todas las tablas L0-L3 volviendo a marcar esas páginas en el bitmap (con limpieza a cero igual que cualquier otra página de datos).

18. **Espacios de direcciones virtuales por proceso:**
    - Cada proceso usuario tiene su propio espacio de direcciones virtual aislado
    - Comienza con 4KB de memoria virtual asignado (heap inicial)
    - Crece dinámicamente en incrementos de 4KB bajo demanda (detectado mediante page faults)
    - Rango virtual disponible para procesos user: desde 0x00000000 hasta 0x6FFFFFFF (1.75GB, reserva para stack)
    - Stack inicial: 64KB por proceso, puede crecer en saltos de 64KB hasta agotar `RAM_total - kernel - 4MB` (el espacio máximo asignable a userland).
    - Stack reside en rango virtual alto [0x7FFFFFFFFFFF downward]
    - **Kernel mapeado en TTBR0:** Solo el código necesario para trampas (vector table, stubs de SVC/IRQ) permanece mapeado en región alta (0xFFFF800000000000+) en modo read-only para EL0. Las tablas de procesos, bitmap y mailboxes **no** se mapean en TTBR0 y solo existen en TTBR1 para EL1.
    - Cada proceso tiene su propia tabla de páginas (TTBR0_EL1 en ARMv8) con 4 niveles
    - **ASLR:** Utiliza un PRNG tipo Linear Congruential Generator (`state = state * 6364136223846793005 + 1`) sembrado con `CNTVCT_EL0`, ID del core y ruido del SoC. El resultado determina offsets independientes para heap y stack en cada proceso (sin usar `core::hash`).

19. **Invalidación de TLB (Translation Lookaside Buffer):**
    - Cuando Core 0 modifica la tabla de páginas de un proceso activo en Core N:
      1. Core 0 actualiza la entrada de página.
      2. Core 0 envía IPI a Core N mediante GIC (Generic Interrupt Controller).
      3. Instrucción ARMv8: `MSR ICC_SGI1R_EL1, Xn` (Send SGI - Software Generated Interrupt).
      4. Core N recibe excepción de nivel 1.
      5. Handler invalida TLB: `TLBI VMALLE1` (invalidate all) o específico `TLBI VAE1, Xn` y luego ejecuta `DSB SY`/`ISB`.
      6. Core N reanuda ejecución con cambios vigentes.
    - **Migración entre cores:** Core 0 envía IPIs tanto al core origen como al destino. El origen invalida su TLB antes de soltar el PCB y el destino invalida nuevamente tras mapearlo, asegurando que ninguna entrada obsoleta quede en cachés distintas.

20. **Protecciones de acceso (ARMv8 Exception Levels y permisos):**
    - Kernel (Core 0): ejecuta **exclusivamente** en EL1. Nunca carga código user.
    - Usuario (Cores 1-N): ejecutan en EL0; solo suben momentáneamente a EL1 para atender una interrupción/SVC y regresan inmediatamente.
    - PTE Access Permission (AP) bits previenen acceso no autorizado:
      - `AP[2:1] = 00`: EL1 solo (kernel)
      - `AP[2:1] = 01`: EL1 lectura/escritura, EL0 solo lectura
      - `AP[2:1] = 10`: EL1 lectura/escritura, EL0 no permitido (protección)
      - Acceso violado genera excepción: `Data Abort Exception`
    - Solo funciones del kernel (Core 0) pueden crear, modificar o destruir tablas de páginas
    - Procesos user no pueden acceder ni modificar páginas del kernel
    - Tablas de páginas de procesos mapean read-only en memoria virtual (solo Core 0 puede modificar) y permanecen fuera de TTBR0 de userland.

## Gestión de Memoria Física

21. **Estructura: PhysicalMemoryManager con Bitmap:**
    - Responsable de trackear y asignar toda la memoria física disponible para procesos user
    - Implementada como bitmap (array de `u64`), donde cada bit representa un frame de página (4KB)
    - Bit en 0 = página libre, Bit en 1 = página ocupada
    - Mantenida exclusivamente por Core 0
    - Completamente implementada en `core` sin dependencias externas (bare metal aarch64)
    - **IMPORTANTE:** El bitmap tiene dos zonas lógicas: una para userland y otra para asignaciones de kernel (stacks, tablas L0-L3). Core 0 es el único que puede consumir páginas de la zona de kernel, preservando las reservas críticas.

22. **Asignación de memoria física:**
    - Core 0 busca bits en 0 consecutivos en el bitmap (suficientes para cantidad de páginas solicitada)
    - Si no hay suficientes páginas libres disponibles para satisfacer solicitud: **rechaza la asignación** y retorna error
    - Si hay espacio (respetando reserva de 3MB protegida): marca los bits como 1 (ocupados) y retorna dirección física base
    - Asignación es secuencial simple (first-fit o best-fit por simplicidad inicialmente)

23. **Ciclo de vida de memoria virtual por proceso:**
    - **Creación:** Core 0 crea tabla de páginas (4 niveles), asigna 4KB inicial de heap, mapea región kernel si es necesario, asigna stack inicial (dinámico)
    - **Crecimiento de heap:** Al detectarse page fault en rango de heap, Core 0 asigna 4KB adicionales, actualiza tabla de páginas, invalida TLB remoto si es necesario
    - **Crecimiento de stack:** Al detectarse page fault en rango de stack, Core 0 asigna página del bitmap, mapea en tabla de páginas en dirección virtual decreciente
    - **Stack explosion protection:** Si el crecimiento solicitado consumiría la reserva `RAM_total - kernel - 4MB` o alcanzaría el límite superior del rango virtual `[0x7000_0000, 0x7FFF_FFFF_FFFF]`, se rechaza la asignación y se termina el proceso con segfault.
    - **Liberación:** Cuando proceso termina, Core 0 libera todas sus páginas físicas

24. **Liberación de memoria física (con limpieza):**
    - Cuando un proceso termina o solicita liberación de memoria, Core 0:
      1. Identifica todas las páginas físicas asociadas al proceso (heap, stack user, stack kernel, tablas L0-L3, buffers temporales, mailboxes)
      2. Para cada página:
         - Escribe ceros en toda la página (sobrescritura completa)
         - Loop de verificación: Lee cada palabra (u64) de la página
         - Si alguna palabra != 0:
           - Reescribe esa celda específica con cero
           - Reintenta verificación (intento 2)
           - Si persiste != 0 después de 3 intentos totales de verificación: marca página como `UNUSABLE`, **no** la reasigna (silent failure, no log)
         - Si todo es cero: marca bit en bitmap como 0 (libre)
      3. Actualiza estructura de metadatos del proceso
      4. Invalida TLB del core que ejecutaba el proceso si es necesario
    - **Razón de limpieza:** Previene que datos sensibles de procesos anteriores queden expuestos en memoria para procesos posteriores (security best practice)

25. **Reserva de memoria para kernel:**
    - Se aparta un bloque total de **4MB** inmediatamente después del rango del kernel: 3MB para operaciones críticas y 1MB para protección OOM.
    - Este pool no se asigna jamás a procesos en Cores 1-N y alimenta el crecimiento ilimitado de stacks de 64 KB y cualquier buffer urgente del kernel.
    - Garantiza que el kernel nunca quedará sin recursos incluso si el userland consume toda la RAM disponible.
    - Core 0 rechaza solicitudes de asignación cuando `available_memory <= 3MB` (mantiene el MB extra intacto como airbag final).

## Excepciones e Interrupciones

26. **Manejo de excepciones (ARMv8 Vector Table):**
    - Vector table vive en rango kernel, base direccionada por `VBAR_EL1`
    - Inicializado por Core 0 durante bootstrap
    - Handlers para cada tipo de excepción:

27. **Page Faults (Data Abort):**
    - **Generado por MMU:** Cuando proceso accede a dirección no mapeada o sin permisos
    - **Componentes de excepción:** Virtual address en `FAR_EL1` (Fault Address Register), tipo en `ESR_EL1` (Exception Syndrome Register)
    - **Handler en Core N:**
      1. Identifica tipo de fault (translation, permission, alignment, etc.)
      2. **Si es acceso a stack (rango 0x70000000 - 0x7FFFFFFFFFFF):**
         - Verifica que nueva página solicitada no exceda límite: `RAM_total - kernel - 4MB reservas`
         - Si hay memoria disponible: envía syscall a Core 0 (`sys_page_fault`) para asignar nuevo bloque de 64KB
         - Si no hay memoria: rechaza asignación, termina proceso con segfault
      3. **Si es acceso a heap (rango 0x00000000 - 0x6FFFFFFF):**
         - Verifica que es acceso válido dentro de límites del proceso
         - Envía syscall a Core 0 para asignar 4KB adicionales
      4. **Si es acceso a memoria kernel desde EL0:** genera segmentation fault → termina proceso
      5. Core 0 procesa: asigna página física, mapea en tabla de páginas, invalida TLB
      6. Retorna a Core N, reintenta acceso
    - **Protección stack overflow:** Si intenta escribir/leer fuera de stack asignado y no hay memoria disponible (OOM protection 1MB), genera segfault automático

28. **Segmentation Fault (acceso a memoria kernel o permiso denegado):**
    - **Generado:** Page fault a dirección kernel desde EL0, o violación de permisos
    - **Acción:** Core N termina proceso automáticamente
      1. Marca estado de proceso como TERMINATED
      2. Solicita Core 0 liberar recursos (via mailbox o syscall)
      3. Core 0 libera memoria con limpieza a ceros
      4. Selecciona siguiente proceso en cola de Core N
    - No hay signal `SIGSEGV` aún (futuro soporte)

29. **Interrupciones por prioridad (ARMv8 GIC):**
    - **Prioridad:** IPI (SGI) > Timer (PPI) > Otros IRQ
    - **Generic Interrupt Controller (GIC)** maneja distribuciónde interrupciones
    - **Timer interrupt (cada 5ms):**
      - Generado por ARM Generic Timer (CNTV_TVAL_EL0)
      - Core 0: dispara scheduling decision
      - **No cambia proceso si está en WAITING_SYSCALL:** syscalls son atómicos, no se interrumpen
      - Cores 1-N: puede generar context switch si hay mejor proceso
    - **IPI (Inter-Processor Interrupt):**
      - Enviado por Core 0 via `MSR ICC_SGI1R_EL1`
      - Usado para:
        - TLB invalidation en Core N
        - Notificación de mailbox con syscall request (Core N → Core 0)
        - Notificación de mailbox con response (Core 0 → Core N)
      - Core N acknowledges y ejecuta handler

## Syscalls - Interfaz de Comunicación

30. **Llamadas a sistema (SVC instruction):**
    - Cores 1-N usan instrucción `SVC #0` para generar excepción (número en SVC no se usa, número real va en X8)
    - Exception Level salta a EL1, handler ejecuta en Core N mismo
    - **Convención de llamada (compatible con Linux aarch64):**
      - X8: número de syscall (identificador, ver https://blog.xhyeax.com/2022/04/28/arm64-syscall-table/)
      - X0-X5: argumentos de syscall
      - X0: retorno (resultado o error code negativo compatible con errno de Linux)
    - **Módulo de syscalls con feature flag:**
      - Syscalls definidas en módulo separado: `syscall/linux.rs`
      - Compilable con `cargo build --features syscall_linux`
      - Permite futuro soporte de otros conjuntos de syscalls (ej: syscall_posix, syscall_custom)
      - Códigos de error compatibles con errno de Linux (ENOMEM=-12, EINVAL=-22, EACCES=-13, etc.)
    - **Números de syscall principales (compatible Linux aarch64):**
      - 1: `sys_exit(exit_code)`
      - 11: `sys_execve(path, argv, envp)` - adaptado como `sys_exec`
      - 57: `sys_fork()` (futuro)
      - 61: `sys_wait4(pid, status, options, rusage)` - reducida internamente a `sys_wait`
      - 98: `sys_futex()` (futuro)
      - 101: `sys_nanosleep()` - usar para sleep (futuro soporte eventos)
      - 140: `sys_setpriority(which, who, prio)` - solo root
      - 160: `sys_uname()`
      - 214: `sys_brk()` - ajustar heap
      - Custom: `sys_page_fault(virtual_addr, type)` - interno, no expuesto a usuario

31. **Mecanismo de Mailbox (comunicación asincrónica):**
    - **Objetivo:** Core N solicita recurso, espera bloqueado mientras Core 0 procesa
    - **Estructura de Mailbox:**
      - Un mailbox por proceso (parte del PCB)
      - Request: `{ syscall_number: u32, args: [u64; 6], pid: u64 }`
      - Response: `{ return_code: i64, data: [u64; 4] }`
      - Vive en la tabla maestra alojada en TTBR1 y no se mapea en TTBR0. Solo se puede leer/escribir mientras el core está en EL1 dentro del handler.
    - **Flujo completo:**
      1. Proceso user ejecuta `SVC #0` con número de syscall en X8
      2. Handler SVC en Core N (EL1):
         - Guarda **todos los registros** en PCB del proceso
         - **Core N cambia estado del proceso a WAITING_SYSCALL**
         - Llena campo `mailbox_request` del PCB con número y argumentos
         - Ejecuta `DMB ishst` para asegurar que los datos estén visibles antes de avisar
         - Core N envía IPI a Core 0 (notificación de mailbox no-vacío)
         - Core N se bloquea esperando respuesta (sin timeout)
      3. Core 0 recibe IPI:
         - Detecta proceso con mailbox_request no-vacío
         - Procesa syscall (asigna memoria, crea proceso, etc.)
         - Escribe resultado en `mailbox_response` del PCB
         - Ejecuta `DMB ish` + `DSB ish` y recién después envía IPI a Core N
      4. Core N recibe IPI:
         - Hace `DMB ish` antes de leer `mailbox_response`
         - Lee `mailbox_response`
         - Escribe retorno en X0 del proceso
         - **Core N cambia estado del proceso de WAITING_SYSCALL a RUNNING**
         - Restaura todos los registros
         - Reanuda ejecución del proceso (retorna de SVC)
    - **Espera:** Core N espera indefinidamente hasta IPI de respuesta. Si Core 0 falla, todo el sistema cae, por lo que no se implementa timeout adicional.

32. **Syscalls principales (primeros):**
    - **Validación previa:** Antes de procesar cualquier syscall, Core 0 valida que todos los punteros provengan del rango user `[0x00000000 - 0x7FFFFFFF]`. Si un puntero apunta a kernel space, la syscall falla con `-EFAULT` y el proceso puede ser terminado.
    - `sys_exit(exit_code)`: Terminar proceso (syscall 1)
      - Cambia el estado a `ZOMBIE`.
      - Libera inmediatamente memoria del proceso: heap, stack user, stack kernel privado, tablas L0-L3 y objetos adicionales.
      - Conserva el PCB y el `exit_code` hasta que el padre ejecute `sys_wait`.
      - Si el padre murió o no hace `wait()`, Core 0 delega el PCB a `init` (PID 1), que periódicamente reaper los zombies.
      - Limpia todas las páginas con ceros (3 intentos de verificación) antes de retornarlas al bitmap.
    - `sys_exec(path, argv, uid, gid)`: Crear y ejecutar proceso (syscall 11 - execve adaptado)
      - **Validación UID/GID:** 
        - Proceso hijo hereda UID del padre por defecto
        - Si `privileged_binaries` marca setuid (o, en el futuro, el bit `S_ISUID` del archivo en el filesystem): UID = UID del propietario registrado
        - Regla: padre UID 1000 NO puede ejecutar binarios UID 0 (salvo con setuid, ej: `su`)
        - Solo root (UID 0) puede ejecutar cualquier binario
        - UIDs válidos para userland se restringen a 0 o al rango [1000, 2000]; si se solicita uno fuera de rango, `sys_exec` retorna `-EINVAL`.
        - Límite anti fork-bomb: rechaza si el UID (≠0) alcanzó 10 000 procesos vivos con `-EAGAIN`
        - Si el `user_process_arena` no puede crecer (free_list vacío tras `grow_if_needed()`), retorna `-EAGAIN` para exponer la misma condición de saturación.
        - **Secuencia anti-saturación:**
          1. `ProcessQuotaManager::reserve_slot(uid)` se ejecuta dentro de una sección crítica corta (spinning máximo 3 reintentos) que primero verifica `global_in_use` y `per_uid`.
          2. Si ambos límites están disponibles, `reserve_slot` extrae un índice del `free_list` y devuelve un handle `{index, uid}`.
          3. Si alguna cuota falla, la función retorna `Err(SysError::EAGAIN)` y `sys_exec` no asigna memoria ni toca el bitmap.
          4. En caso de fallo posterior (por ejemplo ELF inválido), `rollback_slot(handle)` revierte todo evitando fugas.
      - **Parsing de binario ELF64:**
        - Validar magic number (0x7F 'E' 'L' 'F'), clase (64-bit), machine (aarch64)
        - Si inválido o corrupto: rechaza exec con error ENOEXEC (-8)
        - Lee todas las cabeceras según especificación Linux Foundation (Elf64_Ehdr)
      - **Carga de binario en memoria (proceso Linux estándar):**
        1. Leer `e_entry` (entry point), `e_phoff`, `e_phnum`
        2. Iterar program headers (Elf64_Phdr), para cada PT_LOAD:
           - Asignar páginas físicas necesarias (`p_memsz / 4KB`)
           - Mapear en tabla de páginas en `p_vaddr` con permisos según `p_flags` (PF_R, PF_W, PF_X)
           - Copiar `p_filesz` bytes del ELF al espacio virtual del proceso (no se ejecuta directamente desde memoria física compartida)
           - Si `p_memsz > p_filesz`: llenar resto con ceros (sección .bss)
      - **Setup de stack inicial:**
        - Asignar 64KB inicial en región alta (0x7FFFFFFFFFFF downward)
        - Mapear en tabla de páginas con permisos RW (no X)
        - Colocar `argc` en top de stack
        - Colocar punteros `argv[]` debajo de argc
        - Colocar strings de argumentos al final
        - SP apunta a argc
      - **Setup de registros iniciales:**
        - PC = `e_entry` (entry point del ELF)
        - SP = top de stack (apuntando a argc)
        - X0 = argc
        - X1 = puntero a argv
        - Resto de registros en 0 (incluidos FP)
      - **Creación de tablas de páginas (4 niveles L0-L3):**
        - Core 0 asigna páginas físicas para L0, L1, L2, L3 del bitmap
        - Inicializa tablas vacías
        - Copia mapeo de kernel en región alta (0xFFFF800000000000+) con permisos RO para EL0
        - Mapea binario ELF inmediatamente (no lazy)
        - TTBR0_EL1 = dirección física de L0
      - **argv:** `argv_kernel_copy` se usa solo para depurar. Si la concatenación de argumentos supera 1024 bytes, `sys_exec` falla con `-E2BIG` para evitar truncamientos silenciosos.
      - **Setuid sin filesystem:** Mientras no exista un filesystem real, el kernel mantiene una tabla embebida (`privileged_binaries`) con rutas y flags setuid. Esta tabla simula lo que en Linux proviene de los metadatos FS; al portar un FS real, el chequeo migrará a los permisos del inodo.
        - **Construcción teórica:** `build.rs` genera `privileged_binaries.rs` a partir de un archivo declarativo (`privileged_binaries.toml`). Cada entrada contiene `{ path: [u8;256], owner_uid: u32, owner_gid: u32, allowed_callers_mask: [u64; 16], setuid: bool }` (1024 bits para cubrir UID 0 y el rango 1000-2000) y se guarda en un `static` marcado `#[link_section = ".rodata"]`.
        - **Protección:** En el arranque, Core 0 calcula SHA-256 del bloque `privileged_binaries` y lo compara con un hash precalculado `PRIV_BIN_TABLE_HASH` también en `.rodata`. Como el bloque solo se mapea en TTBR1 read-only, Cores 1-N no pueden modificarlo. La única forma de alterarlo es recompilar el kernel o corromper la imagen firma; por eso el hash se imprime al boot para detectar cambios.
        - **Actualización:** Mientras no exista filesystem real, agregar/quitar un binario privilegiado implica editar el archivo declarativo y recompilar. Cuando haya FS, el mismo framework leerá el bit `S_ISUID` y usará la tabla solo como fallback legacy.
      - **Algoritmo de reserva/liberación (plan de recursos):**
        1. `reserve_slot(uid)` entrega `{pcb_index, claim_handle}` y crea un `ProcessMemoryPlan` vacío.
        2. Core 0 reserva el stack de kernel (64KB) del pool protegido, marca su guard page y anota el frame en el plan.
        3. Reserva las tablas de páginas L0-L3 desde la zona “kernel only”, adornando cada frame en el plan.
        4. Reserva páginas iniciales de userland: heap (4KB) y stack (64KB) desde el bitmap general.
        5. Carga los segmentos del ELF en páginas recién asignadas, añadiéndolas al plan hasta que todas las copias hayan sido exitosas.
        6. Si alguna etapa falla (ELF inválido, falta de memoria, verificación setuid, etc.), se invoca `plan.rollback()` que itera la lista de frames en orden inverso, los limpia y los devuelve al bitmap/pool antes de liberar el `claim_flag` y llamar a `rollback_slot`.
        7. Si todo sale bien, `plan.commit()` marca cada frame como definitivo: vincula las tablas a `ttbr0`, publica el stack kernel en el PCB y deja `claim_flag` en `true` hasta que Core N lo ejecute por primera vez.

        **Pipeline recomendado para `privileged_binaries`:**
        1. `privileged_binaries.toml` vive en el repo (rastreado por git) y soporta sintaxis declarativa:
           ```toml
           [[binary]]
           path = "/sbin/init"
           owner_uid = 0
           owner_gid = 0
           allowed_callers = [0, 1000, 1001]  # lista de UID autorizados
           setuid = true
           ```
        2. `build.rs` lee el TOML, valida rutas (máx 255 bytes, ASCII) y genera `OUT_DIR/privileged_binaries.rs` con dos símbolos:
           - `pub static PRIVILEGED_BINARIES: [PrivilegedBinary; N];`
           - `pub static PRIV_BIN_TABLE_HASH: [u8; 32];` (SHA-256 del bloque previo).
        3. Durante el build, `build.rs` también genera una prueba de integridad: escribe el hash en `logs/privileged_binaries.sha256` para que QA lo firme.
        4. `kernel/src/syscall/exec.rs` incluye el archivo generado con `include!(concat!(env!("OUT_DIR"), "/privileged_binaries.rs"));` y marca ambos símbolos con `#[link_section = ".rodata"]` + `#[no_mangle]` para que el linker no los optimice.
        5. En `kernel::main`, antes de habilitar interrupciones, Core 0 recalcula SHA-256 (usando la misma rutina que se emplea para limpieza de páginas) y compara con `PRIV_BIN_TABLE_HASH`. Si falla, se hace `panic!("privileged_binaries tampered")`.
        6. La región se mapea únicamente en TTBR1 y se exporta como `&'static [PrivilegedBinary]` read-only. Para evitar lecturas desde EL0, la dirección virtual se configura fuera del rango compartido (`0xFFFF_9000_0000_0000`).
        7. Cada entrada incluye `allowed_callers_mask` de 1024 bits; `sys_exec` convierte un UID en bit (`bit = uid == 0 ? 0 : (uid - 1000) + 1`) y verifica el word correspondiente (`mask[bit / 64] & (1 << (bit % 64))`).
        8. Cuando exista filesystem real, el pipeline seguirá generando la tabla pero se marcará como "modo compatibilidad". Una vez el FS reporte `S_ISUID`, el TOML se puede vaciar y el hash se mantendrá estable (sum = hash de arreglo vacío).
      - Asignación a Core N menos cargado (medido por cantidad de procesos RUNNING)
      - Prioridad heredada del padre
    - `sys_page_fault(virtual_addr, type)`: Pedir más memoria (interno)
      - Valida que hay memoria disponible (respetando 4MB reservas)
      - Asigna bloque (4KB heap, 64KB stack)
      - Mapea en tabla de páginas
      - Invalida TLB
    - `sys_wait(pid)`: Leer `exit_code` del hijo
      - Bloquea al padre hasta que el hijo cambie a `ZOMBIE`.
      - Devuelve `exit_code` y libera el PCB (estado `TERMINATED`).
      - Si el hijo no existe devuelve `-ECHILD`.
    - `sys_brk(addr)`: Ajustar heap (syscall 214)
    - `sys_setpriority(which, who, prio)`: Cambiar prioridad (syscall 140)
      - Validación: solo root (UID 0) puede cambiar prioridad
      - Retorna EACCES (-13) si no es root
    - `sys_nanosleep(req, rem)`: Dormir proceso (syscall 101) - futuro soporte con eventos
      - Por ahora: marca `is_running=false`, Core 0 salta proceso en scheduling
      - Futuro: despertar con evento o timeout

## Bootstrapping del Sistema

33. **Secuencia de inicialización (Core 0):**
    1. **Setup de CPU:**
       - Inicializar `VBAR_EL1` con la excepción table.
       - Configurar `TTBR1_EL1` con la tabla 1:1 del kernel (todas las estructuras críticas viven aquí).
       - Mantener `TTBR0_EL1` en cero hasta que exista el primer proceso user; en ese momento se cargará con la tabla L0 correspondiente.
       - Configurar `MAIR_EL1` y `TCR_EL1` para habilitar ambos espacios (TTBR0/TTBR1) con los atributos deseados.
       - Habilitar la MMU en `SCTLR_EL1` (bit para TTBR1 activo) y caches.
    2. **Leer Device Tree Blob (DTB):**
       - Leer constante `DTB_OFFSET` desde `main.rs` (configurable por plataforma).
       - Default para Raspberry Pi 4B+: `const DTB_OFFSET: usize = 0x33c;`.
       - Parsear DTB básico (cantidad de memoria RAM, cores, periféricos básicos).
       - Tras parsear, remapear la región del DTB como read-only en TTBR1 para evitar modificaciones accidentales.
    3. **Inicializar bitmap de memoria física:**
       - Marcar rango kernel como ocupado (primeros 10MB)
       - Marcar el pool reservado para stacks de kernel (bloques de 64 KB + guard page) como ocupado inicialmente; se irá liberando/asignando por PCB.
       - Marcar rango reserva como ocupado (4MB: 3MB kernel + 1MB OOM protection) y etiquetarlo como "solo Core 0" para que nunca se entregue a procesos usuario.
       - Resto disponible para asignación
    4. **Inicializar tablas de procesos:**
       - `kernel_process_table`: `[ProcessControlBlock; KERNEL_MAX_PROCESSES]`.
       - `user_process_arena`: reservar el primer slab de 64 PCBs en TTBR1 y empujar todos sus índices al `free_list` con tag cero.
       - Ambas estructuras permanecen en TTBR1 y se limpian a cero.
    5. **Inicializar array de punteros por core:**
       - `[current_process_ptr; NUM_CORES]` en memoria kernel
       - Doble mapeo: versión real en TTBR1 + página dedicada por core en TTBR0 con solo su entrada read-only
    6. **Inicializar Generic Timer para scheduling:**
       - Configurar `CNTV_TVAL_EL0` con valor para 5ms
       - Habilitar timer en `CNTV_CTL_EL0`
       - Registrar handler en vector table (solo Core 0 recibe interrupts)
    7. **Inicializar GIC (Generic Interrupt Controller):**
       - Configurar distribuidor (GICD)
       - Configurar CPU interface (GICC)
       - Habilitar SGI (Software Generated Interrupts) para IPI
       - Configurar prioridades: IPI > Timer > otros
    8. **Inicializar stacks de kernel:**
       - Reservar bloques de 64 KB + guard page para cada PCB que se vaya creando (Core 0 tiene el suyo desde el arranque).
       - Configurar manejo de page fault para crecer el stack cuando se acerque a la guard page.
    9. **Inicializar UART:**
       - Dirección física depende de SBC (configurado en drivers específicos)
       - Para Raspberry Pi 4B+: usar driver específico de RPi
       - UART como stdout/stdin solo para texto (no video, no audio)
    10. **Cargar init (primer proceso user):**
        - Llamar `sys_exec("/sbin/init", NULL, 0, 0)`
        - Asignar a Core 1 (first user core)
    11. **Levantar Cores 1-N:**
        - Escribir en registros específicos del SoC para despertar cores secundarios
        - Cada Core inicializa su VBAR_EL1, lee su puntero de proceso
        - Cada Core entra en loop de ejecución
    12. **Core 0 entra en loop de scheduling:**
        - Espera timer interrupts cada 5ms
        - Procesa mailboxes con syscalls pendientes
        - Evalúa prioridades, actualiza punteros, envía IPIs si es necesario
        - Puede migrar procesos entre cores (cambiando punteros, guardando contexto completo)

## Parsing de Binarios ELF

34. **Carga de binarios ejecutables (formato ELF64):**
    - Formato ELF64 (Executable and Linkable Format) para todos los binarios user
    - Core 0 parsea header ELF cuando se crea proceso:
      - **Validaciones iniciales:**
        - Magic number: `0x7F 'E' 'L' 'F'` (primeros 4 bytes)
        - Clase: ELF64 (64-bit)
        - Machine type: aarch64 (ARM 64-bit)
        - Version: EV_CURRENT (1)
        - Si falla alguna validación: rechaza con ENOEXEC (-8)
      - **Estructura completa de Elf64_Ehdr según Linux Foundation:**
        ```
        typedef struct {
            unsigned char   e_ident[EI_NIDENT];  /* Magic, clase, endianness */
            Elf64_Half      e_type;               /* Tipo: ET_EXEC, ET_DYN */
            Elf64_Half      e_machine;            /* Arquitectura: EM_AARCH64 */
            Elf64_Word      e_version;            /* Versión ELF */
            Elf64_Addr      e_entry;              /* Entry point */
            Elf64_Off       e_phoff;              /* Program header offset */
            Elf64_Off       e_shoff;              /* Section header offset */
            Elf64_Word      e_flags;              /* Flags específicos de arquitectura */
            Elf64_Half      e_ehsize;             /* ELF header size */
            Elf64_Half      e_phentsize;          /* Program header entry size */
            Elf64_Half      e_phnum;              /* Cantidad de program headers */
            Elf64_Half      e_shentsize;          /* Section header entry size */
            Elf64_Half      e_shnum;              /* Cantidad de section headers */
            Elf64_Half      e_shstrndx;           /* Index de string table */
        } Elf64_Ehdr;
        ```
      - Extrae entry point (`e_entry`)
      - Lee program headers (segments a cargar)
      - **Setuid mechanism (inspirado en Linux):**
        - Linux consulta el bit `S_ISUID` en los permisos del inodo. Cuando exista un filesystem real, replicaremos esa lógica leyendo directamente los metadatos del archivo.
        - Mientras tanto, el kernel mantiene la tabla embebida `privileged_binaries` con rutas y flags setuid para simular esos metadatos.
        - Cada entrada incluye `allowed_callers_mask` de 1024 bits tal como se describió anteriormente; `sys_exec` convierte el UID en bit y rechaza la ejecución si la máscara no habilita explícitamente a ese UID.
        - Si una entrada marca `setuid`, Core 0 valida que el proceso padre pueda ejecutarla; si es válido, el nuevo proceso hereda el UID del propietario registrado, en caso contrario devuelve `EACCES (-13)`.

## Debugging, Testing e Introspección

35. **Funciones de introspección del scheduler:**
    - `print_scheduler_state()`: Imprime estado actual de cada scheduler por core (core, proceso actual, PID, prioridad, estado)
    - `print_process_table()`: Lista todos los procesos en tabla maestra (PID, UID/GID, prioridad, estado, TTBR0)
    - `print_memory_state()`: Muestra estado del bitmap (páginas libres, ocupadas, fragmentación, 4MB reservados)
    - `print_core_status()`: Para cada Core N, muestra el puntero actual y proceso que está ejecutando
    - `print_exception_state()`: Muestra últimas 64 excepciones manejadas (buffer circular), FAR_EL1, ESR_EL1, tipo, timestamp
    - Todas estas funciones usan `println!` macro para output por UART

36. **Funciones de testing básicas:**
    - `test_bitmap_allocation()`: Verifica que asignación y liberación de páginas en bitmap funciona correctamente
    - `test_process_creation()`: Crea procesos de prueba, verifica tabla maestra
    - `test_priority_scheduling()`: Verifica que Core 0 scheduling respeta prioridades
    - `test_context_switch()`: Simula context switch, verifica todos los registros se guardan correctamente
    - `test_memory_cleanup()`: Verifica que páginas liberadas se sobrescriben con ceros y verifica lectura posterior
    - `test_page_fault_handling()`: Genera page fault controlado, verifica que se asigna página correcta
    - `test_segfault()`: Genera acceso a memoria kernel desde EL0, verifica que termina proceso
    - `test_ipi_tlb_invalidation()`: Simula modificación de página table con IPI a otro core
    - Estas funciones deben ser ejecutables desde binario de prueba early en boot, accesibles via feature flags
